services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    restart: always
    ports:
      - "8080:8080"
    env_file:
      - .env
    depends_on:
      - redis
    volumes:
      - ./data/backend:/app/data

  pusher:
    build:
      context: .
      dockerfile: backend/pusher/Dockerfile
    restart: always
    ports:
      - "8081:8080"
    env_file:
      - .env
    depends_on:
      - redis

  frontend:
    build:
      context: .
      dockerfile: web/frontend/Dockerfile
      args:
        - API_URL=http://localhost:8080
        - NEXT_PUBLIC_FIREBASE_API_KEY=${NEXT_PUBLIC_FIREBASE_API_KEY:-fake_key_for_build}
        - NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=${NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN:-omi-app.firebaseapp.com}
        - NEXT_PUBLIC_FIREBASE_PROJECT_ID=${NEXT_PUBLIC_FIREBASE_PROJECT_ID:-omi-app}
        - NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET=${NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET:-omi-app.appspot.com}
        - NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=${NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID:-123456789}
        - NEXT_PUBLIC_FIREBASE_APP_ID=${NEXT_PUBLIC_FIREBASE_APP_ID:-1:123456789:web:abcdef}
        - NEXT_PUBLIC_FIREBASE_MEASUREMENT_ID=${NEXT_PUBLIC_FIREBASE_MEASUREMENT_ID:-G-ABCDEF}
    restart: always
    ports:
      - "3000:3000"
    env_file:
      - .env
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - backend

  redis:
    image: redis:alpine
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data

  # Optional: Diarizer (Requires NVIDIA GPU and NVIDIA Container Toolkit)
  # diarizer:
  #   build:
  #     context: .
  #     dockerfile: backend/diarizer/Dockerfile
  #   restart: always
  #   ports:
  #     - "8082:8080"
  #   env_file:
  #     - .env
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]
