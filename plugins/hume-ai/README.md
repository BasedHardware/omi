# ğŸ­ Omi Audio Emotion Analysis with Real-time Notifications

A Python FastAPI service that receives real-time audio from Omi devices, analyzes emotions using Hume AI, sends automatic notifications, and provides a beautiful dashboard with emotion statistics.

## ğŸ“¸ Screenshots

### Dashboard
![Rizz Meter Dashboard](./image/rizzmeter.png)

### Omi Mobile App Notification
<img src="./image/omi phone ss.png" alt="Omi Phone Notification" width="300"/>

### App Setup Video
[ğŸ“¹ Watch Setup Tutorial](./video/rizz-omi-setup.mov)

## âœ¨ Features

- ğŸ¤ **Real-time Audio Streaming** from Omi devices
- ğŸ§  **Emotion Analysis** using [Hume AI's Speech Prosody Model](https://www.hume.ai/products/speech-prosody-model) & Language models
- ğŸ“± **Automatic Notifications** via Omi app when emotions are detected
- ğŸ“Š **Live Dashboard** with emotion statistics and percentages
- âš™ï¸ **Configurable Thresholds** for emotion detection
- ğŸ“ˆ **Emotion Tracking** with cumulative counts and visualizations
- ğŸ”„ **Auto-chunking** for audio files longer than 5 seconds
- ğŸ—‘ï¸ **Statistics Reset** button on dashboard
- ğŸ³ **Docker Support** for easy deployment

## ğŸš€ Quick Start

Choose your deployment method:

### Option A: Deploy to Render (Easiest - 5 minutes)

**Step 1: Get Your API Keys**

1. **Hume AI** (Required)
   - Sign up at [Hume AI](https://www.hume.ai/)
   - Create an API key from your dashboard
   - Copy your key

2. **Omi Integration** (Required for Notifications)
   - Open **Omi mobile app**
   - Go to **Apps** â†’ **Create App**
   - Select **External Integration** â†’ **Notifications**
   - Name it "Emotion AI Notifier"
   - Copy your **App ID** and **API Key**

**Step 2: Deploy to Render**

[![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy)

1. Click the "Deploy to Render" button above
2. Connect your GitHub account
3. Set these environment variables in Render:
   ```bash
   # Required
   HUME_API_KEY=your_hume_api_key
   OMI_APP_ID=your_omi_app_id
   OMI_API_KEY=your_omi_api_key
   ```
4. Click "Create Web Service"
5. Wait for deployment to complete (~5 minutes)

**Step 3: Configure Omi App**

**Part A: Enable Audio Streaming**

1. Open **Omi mobile app**
2. Go to **Settings** â†’ **Developer Mode**
3. Toggle **Developer Mode** ON
4. Scroll down to **"Realtime Audio Bytes"**
5. Toggle **Enable** ON
6. Enter your Render URL:
   ```
   https://your-app-name.onrender.com/audio
   ```
7. Set **"Every x seconds"** to `5`
8. Click **Save**

**Part B: Create Omi App for Notifications**

1. In Omi app, go to **Apps** tab
2. Click **Create App** (+ button)
3. Select **External Integration**
4. Configure the app:
   - **Enable Memories**: Toggle ON
   - **Trigger Event**: Select **Audio Bytes**
   - **Webhook URL**:
     ```
     https://your-app-name.onrender.com/audio
     ```
   - **App Home URL**:
     ```
     https://your-app-name.onrender.com
     ```
5. Click **Save**
6. Click **Install App**

**Part C: Get API Credentials**

1. After installing, go to **Manage Your App**
2. Copy the **App ID** (you'll need this)
3. Scroll down and click **Create API Key**
4. Copy the **API Key** (you'll need this)

**Part D: Update Render Environment Variables**

1. Go to **Render Dashboard**
2. Select your deployed service
3. Click **Environment** tab
4. Update these variables:
   - `OMI_APP_ID` = paste your App ID
   - `OMI_API_KEY` = paste your API Key
5. Click **Save Changes**
6. Wait for automatic redeploy (~2 minutes)

**Step 4: Verify It's Working**

1. Open your dashboard: `https://your-app-name.onrender.com`
2. Speak into your Omi device
3. Check the dashboard for emotion statistics
4. You should receive notifications in the Omi app!

---

### Option B: Run Locally (For Development - 10 minutes)

**Step 1: Clone and Install**

```bash
# Clone repository
git clone https://github.com/your-username/audio-sentiment-profiling.git
cd audio-sentiment-profiling

# Install dependencies
pip install -r requirements.txt

# Install ffmpeg
brew install ffmpeg  # macOS
sudo apt-get install ffmpeg  # Linux
```

**Step 2: Configure Environment**

```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your API keys
nano .env
```

Add your keys to `.env`:
```bash
HUME_API_KEY=your_hume_api_key_here
OMI_APP_ID=your_omi_app_id_here
OMI_API_KEY=your_omi_api_key_here
```

**Step 3: Start the Server**

```bash
# Option 1: Direct run
python main.py

# Option 2: Using start script
./start_server.sh
```

Server will start at `http://localhost:8080`

**Step 4: Expose with ngrok (for Omi device to connect)**

```bash
# In a new terminal
ngrok http 8080

# Copy the ngrok URL (e.g., https://abc123.ngrok.io)
```

**Step 5: Configure Omi App**

1. Open **Omi mobile app**
2. Go to **Settings** â†’ **Developer Mode**
3. Under **"Realtime audio bytes"**, enter:
   ```
   https://your-ngrok-url.ngrok.io/audio
   ```
4. Save and test!

**Step 6: Test It**

1. Open `http://localhost:8080` in your browser
2. Speak into your Omi device
3. Watch the dashboard update in real-time!

---

### Option C: Docker (For Containerized Deployment)

```bash
# Build image
docker build -t omi-emotion-ai .

# Run container
docker run -d -p 8080:8080 \
  -e HUME_API_KEY=your_key \
  -e OMI_APP_ID=your_app_id \
  -e OMI_API_KEY=your_api_key \
  --name omi-emotion \
  omi-emotion-ai

# View logs
docker logs -f omi-emotion
```

Then configure Omi app to point to your Docker host's URL.

## ğŸ¯ How It Works

This plugin uses [Hume AI's Speech Prosody Model](https://www.hume.ai/products/speech-prosody-model) to analyze vocal tone and emotion from audio recordings.

```
User speaks â†’ Omi records â†’ Sends to your server
                               â†“
            Analyze with Hume AI Speech Prosody
                               â†“
                    Detect emotions in top 3
                               â†“
                    Match against configured list
                               â†“
              Send notification automatically!
                               â†“
              ğŸ“± User receives emotion alert
```

## ğŸ“± Notification System

### Automatic Notifications

By default, notifications are sent for **ALL emotions** detected in the top 3. The system is configured in `emotion_config.json`:

```json
{
  "notification_enabled": true,
  "emotion_thresholds": {},
  "notification_message_template": "ğŸ­ Emotion Alert: Detected {emotions}"
}
```

**Empty thresholds = notify for ALL top 3 emotions!**

### Customize Which Emotions Trigger Notifications

Edit `emotion_config.json` to notify only for specific emotions:

```json
{
  "notification_enabled": true,
  "emotion_thresholds": {
    "Joy": 0.5,
    "Anger": 0.6,
    "Sadness": 0.5
  }
}
```

### Configuration Methods

**Method 1: Environment Variable (Recommended for Cloud/Render)**

Best for persistent configuration that survives restarts.

In Render Dashboard â†’ Environment:
```bash
EMOTION_NOTIFICATION_CONFIG={"notification_enabled":true,"emotion_thresholds":{"Joy":0.5,"Anger":0.7}}
```

**Method 2: File (Local Development Only)**

Edit `emotion_config.json` and restart server:
```json
{
  "notification_enabled": true,
  "emotion_thresholds": {
    "Joy": 0.5,
    "Anger": 0.7
  }
}
```

**Method 3: API (Temporary - Lost on Restart)**

For testing only - changes are lost when container restarts:
```bash
# View config
curl https://your-app.onrender.com/emotion-config

# Update config (temporary!)
curl -X POST https://your-app.onrender.com/emotion-config \
  -H "Content-Type: application/json" \
  -d '{"notification_enabled": true, "emotion_thresholds": {"Joy": 0.5}}'
```

âš ï¸ **Note**: API changes don't persist in cloud deployments. Use environment variables for permanent configuration.

### How to Update Configuration on Render

**Option 1: Update Environment Variable (Permanent)**

Changes persist across restarts:

1. Go to **Render Dashboard**
2. Select your service
3. Click **Environment** tab
4. Find `EMOTION_NOTIFICATION_CONFIG`
5. Click **Edit**
6. Update the JSON value:
   ```json
   {"notification_enabled":true,"emotion_thresholds":{"Joy":0.6,"Anger":0.8}}
   ```
7. Click **Save**
8. Render will automatically redeploy (~2-3 minutes)

âœ… Permanent - survives restarts

**Option 2: Use API Endpoint (Temporary)**

Instant update without redeploying:

```bash
curl -X POST https://your-app-name.onrender.com/emotion-config \
  -H "Content-Type: application/json" \
  -d '{
    "notification_enabled": true,
    "emotion_thresholds": {
      "Joy": 0.6,
      "Anger": 0.8
    }
  }'
```

âœ… Instant - takes effect immediately
âŒ Temporary - lost on restart/redeploy

**Good for:** Quick testing and trying different thresholds before committing

## ğŸ“Š Dashboard Features

Access at: `https://your-app.onrender.com/`

### What You'll See:

- âœ… **Configuration Status** - Hume AI & Omi setup
- ğŸ“ˆ **Request Statistics** - Total, successful, failed analyses
- ğŸ•’ **Last Activity** - Most recent request with emotions
- ğŸ­ **Emotion Statistics** - Cumulative counts and percentages with visual bars
- ğŸ—‘ï¸ **Reset Button** - Clear all statistics
- ğŸ”„ **Auto-refresh** - Updates every 10 seconds

### Example Dashboard View:

```
ğŸ¤ Omi Audio Streaming Service ONLINE

âš™ï¸ Configuration Status
âœ“ Hume AI API Key: Configured
âœ“ Omi Integration: Configured

16 Total Requests | 12 Successful | 4 Failed

ğŸ“Š Last Activity
Time: 2025-11-02 18:52:54 UTC
User ID: XqBKRatqZ5MS4tsX84VfBEne16W2
[Joy (0.23)] [Calmness (0.18)] [Interest (0.15)]

ğŸ­ Emotion Statistics
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Joy            Count: 15 | 25.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Calmness       Count: 12 | 20.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Interest       Count: 10 | 16.7% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Excitement     Count: 8  | 13.3% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Satisfaction   Count: 7  | 11.7% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```


## ğŸ­ Available Emotions

Hume AI detects 48+ emotions including:

**Positive:** Joy, Amusement, Satisfaction, Excitement, Pride, Triumph, Relief, Romance, Desire, Admiration, Adoration

**Negative:** Anger, Sadness, Fear, Disgust, Anxiety, Distress, Shame, Guilt, Embarrassment, Contempt

**Neutral:** Calmness, Concentration, Contemplation, Determination, Interest, Surprise, Confusion, Realization

## ğŸ“‹ Configuration Examples

### Example 1: Safety Monitoring
```json
{
  "emotion_thresholds": {
    "Anger": 0.8,
    "Fear": 0.85,
    "Distress": 0.8
  }
}
```
â†’ Only high-intensity negative emotions

### Example 2: Mental Health Support
```json
{
  "emotion_thresholds": {
    "Sadness": 0.5,
    "Anxiety": 0.55,
    "Distress": 0.5
  }
}
```
â†’ Early detection of emotional distress

### Example 3: Positive Reinforcement
```json
{
  "emotion_thresholds": {
    "Joy": 0.7,
    "Pride": 0.75,
    "Triumph": 0.8
  }
}
```
â†’ Celebrate achievements!

### Example 4: All Emotions (Default)
```json
{
  "emotion_thresholds": {}
}
```
â†’ Notify for ALL top 3 emotions

## âš™ï¸ Advanced Configuration

### Emotion Thresholds

You can customize which emotions trigger notifications by editing `emotion_config.json`:

**Notify for ALL emotions (default):**
```json
{
  "notification_enabled": true,
  "emotion_thresholds": {}
}
```

**Notify only for specific emotions:**
```json
{
  "notification_enabled": true,
  "emotion_thresholds": {
    "Joy": 0.5,
    "Anger": 0.6,
    "Sadness": 0.5
  }
}
```

**Threshold Guidelines:**

Since Hume AI predicts across 48 emotions, scores are typically lower:
- 0.30-0.50: Good detection (recommended range)
- 0.50-0.70: Strong detection
- 0.70+: Very strong detection (rare)

ğŸ’¡ **Tip**: Start with thresholds around 0.30-0.40 for reliable notifications

### Notification Cooldown

To prevent notification spam, the system enforces a **30-second cooldown** between automatic notifications. This means after sending a notification, the system will wait 30 seconds before sending another one, even if emotions are detected.

**How to Change the Cooldown:**

Edit `app.py` line 53:
```python
# Notification cooldown in seconds (configurable)
NOTIFICATION_COOLDOWN_SECONDS = 30  # Change to your preferred interval
```

Examples:
- `60` = 1 minute cooldown
- `120` = 2 minutes cooldown
- `300` = 5 minutes cooldown

**Note:** The "ğŸ”” Send Notification" button on the dashboard is for testing purposes and bypasses the cooldown to send immediately.

### Environment Variables

All available environment variables:

```bash
# Required
HUME_API_KEY=your_hume_api_key_here          # From platform.hume.ai
OMI_APP_ID=your_omi_app_id_here              # From Omi mobile app
OMI_API_KEY=your_omi_api_key_here            # From Omi mobile app
```

### API Endpoints

**Main Endpoints:**
- `POST /audio` - Receive audio from Omi (main webhook)
- `GET /` - Dashboard with statistics
- `GET /health` - Health check
- `GET /status` - JSON status and stats
- `POST /analyze-text` - Analyze text emotions
- `GET /emotion-config` - View notification config
- `POST /emotion-config` - Update notification config
- `POST /reset-stats` - Reset all statistics

## ğŸ” Troubleshooting

### No Notifications Received?

**Check 1: Render Environment Variables**
```bash
# Verify these are set in Render Dashboard â†’ Environment:
OMI_APP_ID=...
OMI_API_KEY=...
```

**Check 2: Omi App Enabled**
- Open Omi mobile app
- Go to **Apps** â†’ Find your app
- Make sure it's **ENABLED**

**Check 3: Check Logs**
Look for in Render logs:
```
ğŸ”” Notification check: should_notify=True, has_predictions=True
Using config emotion filters: {}
ğŸ“Š Trigger check result: triggered=True, count=3
âœ“ Sent Omi notification to user
```

**Check 4: Verify URL**
```
âœ… https://your-app.onrender.com/audio
âŒ https://your-app.onrender.com/audio?send_notification=true?sample_rate=16000
```
(No extra parameters needed!)

### "No speech detected" Warnings

- Speak clearly during recording
- Check microphone permissions in Omi app
- Test in quiet environment
- Ensure Omi device is working properly

### "Audio too long" Errors

Already fixed! The service automatically chunks audio >5 seconds into 4.5s segments.

### Dashboard Not Showing Emotions

- Hard refresh browser: `Ctrl+Shift+R` (Windows) or `Cmd+Shift+R` (Mac)
- Wait for auto-refresh (10 seconds)
- Check `/status` endpoint for current stats

## ğŸ’¡ Important Notes

**Hume API Limits:**
- Audio files must be â‰¤5 seconds for WebSocket API
- Set "Every x seconds" to 5 in Omi app settings
- The plugin auto-chunks longer audio files

**Contributing:**
- Fork the repo and create a feature branch
- Test your changes thoroughly
- Submit a pull request with a clear description

## ğŸ“ Project Structure

```
audio-sentiment-profiling/
â”œâ”€â”€ main.py                    # Main FastAPI server (1800+ lines)
â”‚   â”œâ”€â”€ Configuration & Setup
â”‚   â”œâ”€â”€ Audio Processing Functions
â”‚   â”œâ”€â”€ Hume AI Integration
â”‚   â”œâ”€â”€ Omi Notifications & Memories
â”‚   â”œâ”€â”€ API Endpoints (/audio, /status, etc.)
â”‚   â””â”€â”€ Dashboard HTML
â”œâ”€â”€ emotion_config.json        # Emotion detection configuration
â”œâ”€â”€ setup.py                   # Python package setup
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Dockerfile                 # Docker configuration
â”œâ”€â”€ render.yaml                # Render deployment config
â”œâ”€â”€ start_server.sh            # Server startup script
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ LICENSE                    # MIT License
â”œâ”€â”€ README.md                  # Main documentation (this file)
â”œâ”€â”€ tests/                     # Test scripts
â”‚   â”œâ”€â”€ test_chunking.py
â”‚   â”œâ”€â”€ test_notification.py
â”‚   â””â”€â”€ test_omi_now.py
â”œâ”€â”€ image/                     # Screenshots
â””â”€â”€ video/                     # Demo videos
```

## ğŸš€ Deployment

### Render (Recommended)

1. Fork this repo
2. Click "Deploy to Render" button above
3. Add environment variables in Render dashboard
4. Deploy!

Your app will be live at: `https://your-app-name.onrender.com`

### Docker

```bash
docker build -t omi-emotion-ai .
docker run -p 8080:8080 \
  -e HUME_API_KEY=... \
  -e OMI_APP_ID=... \
  -e OMI_API_KEY=... \
  omi-emotion-ai
```

## ğŸ¯ Use Cases

- ğŸ’™ **Mental Health Monitoring** - Track emotional patterns
- ğŸ“ **Customer Service** - Alert when customers are frustrated
- ğŸ™ï¸ **Voice Journaling** - Analyze emotional trends
- ğŸ—£ï¸ **Communication Coaching** - Improve emotional delivery
- ğŸ”¬ **Research** - Study emotional responses

## ğŸ§ª Testing

Run tests to verify your setup:

```bash
# Test notification sending
python tests/test_notification.py

# Test audio chunking
python tests/test_chunking.py path/to/audio.wav

# Quick Omi notification test
python tests/test_omi_now.py
```

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

## ğŸ™ Acknowledgments

- [Omi](https://www.omi.me/) - Amazing wearable AI device
- [Hume AI](https://www.hume.ai/) - Powerful emotion analysis
- [Render](https://render.com/) - Easy cloud deployment

---

**Made with â¤ï¸ for better emotional awareness**

For questions or issues, please open an issue on GitHub!
