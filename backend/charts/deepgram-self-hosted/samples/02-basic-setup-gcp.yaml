# See the Chart [README](https://github.com/deepgram/self-hosted-resources/blob/main/charts/deepgram-self-hosted#values)
#   for documentation on all available options.

global:
  # pullSecretRef should refer to a K8s secret that
  # must be created prior to installing this Chart.
  # Consult the [official Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/secret/) for best practices on configuring Secrets for use in your cluster.
  #
  # You can create a secret for your image pull credentials
  # with the following commands:
  # ```bash
  # docker login quay.io
  # kubectl create secret docker-registry dg-regcred \
  #   --docker-server=quay.io \
  #   --docker-username='QUAY_DG_USER' \
  #   --docker-password='QUAY_DG_PASSWORD'
  # ```
  pullSecretRef: "dg-regcred"

  # deepgramSecretRef should refer to a K8s secret that
  # must be created prior to installing this Chart.
  # Consult the [official Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/secret/) for best practices on configuring Secrets for use in your cluster.
  #
  # You can create a secret for your Deepgram self-hosted API key
  # with the following command:
  # ```bash
  # kubectl create secret generic dg-self-hosted-api-key --from-literal=DEEPGRAM_API_KEY='<id>'
  # ```
  deepgramSecretRef: "dg-self-hosted-api-key"

scaling:
  replicas:
    api: 1
    engine: 1
  auto:
    # Can toggle to true to enable autoscaling. Make sure to set a value for one of the available metrics
    enabled: false
    engine:
      metrics:
        speechToText:
          batch:
            requestsPerPod: # Discuss a reasonable value with your Deepgram Account Representative
          streaming:
            requestsPerPod: # Discuss a reasonable value with your Deepgram Account Representative
        textToSpeech:
          batch:
            requestsPerPod: # Discuss a reasonable value with your Deepgram Account Representative
        # Discuss a reasoanble value with your Deepgram Account Representative
        # Must also set engine.concurrencyLimit.activeRequests if using request ratio for autoscaling
        requestCapacityRatio:

api:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: k8s.deepgram.com/node-type
                operator: In
                values:
                  - api
  resources:
    requests:
      memory: "4Gi"
      cpu: "2000m"
    limits:
      memory: "12Gi"
      cpu: "4000m"

engine:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: k8s.deepgram.com/node-type
                operator: In
                values:
                  - engine
  resources:
    requests:
      memory: "24Gi"
      cpu: "5000m"
      gpu: 1
    limits:
      memory: "40Gi"
      cpu: "8000m"
      gpu: 1
  # Discuss a reasonable value with your Deepgram Account Representative
  # If not using autoscaling, can be left empty, but must be set if using
  # autoscaling with scaling.auto.engine.metrics.requestCapacityRatio
  concurrencyLimit:
    activeRequests:
  modelManager:
    volumes:
      gcp:
        gpd:
          enabled: true
          # Replace with your Google disk handle
          volumeHandle: "projects/<your-project-id>/zones/<your-zone>/disks/<your-disk>"

licenseProxy:
  enabled: true

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: k8s.deepgram.com/node-type
                operator: In
                values:
                  - license-proxy
  resources:
    requests:
      memory: "4Gi"
      cpu: "1000m"
    limits:
      memory: "8Gi"
      cpu: "2000m"

gpu-operator:
  # GKE will manage the driver and toolkit installation for us by default.
  enabled: false
