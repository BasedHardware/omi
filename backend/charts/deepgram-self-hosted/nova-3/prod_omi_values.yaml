# See the Chart [README](https://github.com/deepgram/self-hosted-resources/blob/main/charts/deepgram-self-hosted#values)
#   for documentation on all available options.

global:
  # pullSecretRef should refer to a K8s secret that
  # must be created prior to installing this Chart.
  # Consult the [official Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/secret/) for best practices on configuring Secrets for use in your cluster.
  #
  # You can create a secret for your image pull credentials
  # with the following commands:
  # ```bash
  # docker login quay.io
  # kubectl create secret docker-registry dg-regcred \
  #   --docker-server=quay.io \
  #   --docker-username='QUAY_DG_USER' \
  #   --docker-password='QUAY_DG_PASSWORD'
  # ```
  pullSecretRef: "dg-regcred"

  # deepgramSecretRef should refer to a K8s secret that
  # must be created prior to installing this Chart.
  # Consult the [official Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/secret/) for best practices on configuring Secrets for use in your cluster.
  #
  # You can create a secret for your Deepgram self-hosted API key
  # with the following command:
  # ```bash
  # kubectl create secret generic dg-self-hosted-api-key --from-literal=DEEPGRAM_API_KEY='<id>'
  # ```
  deepgramSecretRef: "dg-self-hosted-api-key"

scaling:
  # -- Number of replicas to set during initial installation.
  # @default -- ``
  replicas:
    api: 1
    engine: 1
  auto:
    # Can toggle to true to enable autoscaling. Make sure to set a value for one of the available metrics
    enabled: true

    api:
      metrics:
        # -- Scale the API deployment to this Engine-to-Api pod ratio
        engineToApiRatio: 5

    engine:
      # -- Minimum number of Engine replicas.
      minReplicas: 5
      # -- Maximum number of Engine replicas.
      maxReplicas: 20
      metrics:
        speechToText:
          batch:
            requestsPerPod: # Discuss a reasonable value with your Deepgram Account Representative
          streaming:
            requestsPerPod: 
        textToSpeech:
          batch:
            requestsPerPod: # Discuss a reasonable value with your Deepgram Account Representative
        # Discuss a reasoanble value with your Deepgram Account Representative
        # Must also set engine.concurrencyLimit.activeRequests if using request ratio for autoscaling
        requestCapacityRatio:
        custom:
        - type: External
          external:
            metric:
              name: engine_avg_gpu_utilization
            target:
              type: Value
              value: 60
      behavior:
        scaleUp:
          stabilizationWindowSeconds: 60  # Wait 1 minute before scaling up

api:
  image:
    path: us-central1-docker.pkg.dev/based-hardware/deepgram/self-hosted-api
    tag: release-250331
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: k8s.deepgram.com/node-type
                operator: In
                values:
                  - api
  ingress:
    annotations:
      kubernetes.io/ingress.class: "gce-internal"
      kubernetes.io/ingress.regional-static-ip-name: "prod-omi-deepgram-ilb-ip-address"
      kubernetes.io/ingress.allow-http: "false"
      ingress.gcp.kubernetes.io/pre-shared-cert: "prod-omi-deepgram-ilb-cert"
    hosts:
      - host: dg.omi.me
        paths:
          - path: /
            pathType: Prefix

  resources:
    requests:
      memory: "4Gi"
      cpu: "2000m"
    limits:
      memory: "12Gi"
      cpu: "4000m"

engine:
  image:
    path: us-central1-docker.pkg.dev/based-hardware/deepgram/self-hosted-engine
    tag: release-250331
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: k8s.deepgram.com/node-type
                operator: In
                values:
                  - engine
  resources:
    requests:
      memory: "24Gi"
      cpu: "5000m"
      gpu: 1
    limits:
      memory: "40Gi"
      cpu: "12000m"
      gpu: 1
  # Discuss a reasonable value with your Deepgram Account Representative
  # If not using autoscaling, can be left empty, but must be set if using
  # autoscaling with scaling.auto.engine.metrics.requestCapacityRatio
  concurrencyLimit:
    activeRequests:
  modelManager:
    volumes:
      gcp:
        gpd:
          enabled: true
          # Replace with your Google disk handle
          volumeHandle: "projects/based-hardware/zones/us-central1-a/disks/prod-omi-deepgram-model-storage"

licenseProxy:
  enabled: true
  image:
    path: us-central1-docker.pkg.dev/based-hardware/deepgram/self-hosted-license-proxy
    tag: release-250331
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: k8s.deepgram.com/node-type
                operator: In
                values:
                  - license-proxy
  resources:
    requests:
      memory: "4Gi"
      cpu: "1000m"
    limits:
      memory: "8Gi"
      cpu: "2000m"

gpu-operator:
  # GKE will manage the driver and toolkit installation for us by default.
  enabled: false

kube-prometheus-stack:
  grafana:
    enabled: true
    ingress:
      enabled: true
      annotations:
        kubernetes.io/ingress.class: "gce"
        kubernetes.io/ingress.global-static-ip-name: "prod-omi-deepgram-grafana-alb-ip-address"
        networking.gke.io/managed-certificates: "prod-omi-deepgram-grafana-alb-cert"
        kubernetes.io/ingress.allow-http: "false"
      hosts:
        - dg-monitor.omi.me
      path: /
    persistence:
      enabled: true
      type: sts
      storageClassName: standard-rwo
      accessModes:
        - ReadWriteOnce
      size: 20Gi
      finalizers:
        - kubernetes.io/pvc-protection
  prometheus:
    prometheusSpec:
      additionalScrapeConfigs:
        - job_name: "dg_engine_metrics"
          scrape_interval: "2s"
          kubernetes_sd_configs:
            - role: endpoints
              namespaces:
                names:
                  - "{{ .Release.Namespace }}"
          relabel_configs:
            - source_labels: [__meta_kubernetes_service_name]
              regex: "(.*)-metrics"
              action: keep
            - source_labels: [__meta_kubernetes_endpoint_port_name]
              regex: "metrics"
              action: keep
            - source_labels: [__meta_kubernetes_namespace]
              target_label: namespace
            - source_labels: [__meta_kubernetes_service_name]
              target_label: service
            - source_labels: [__meta_kubernetes_pod_name]
              target_label: pod
        - job_name: gpu-metrics
          scrape_interval: 1s
          metrics_path: /metrics
          scheme: http
          kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
              - gke-managed-system
          relabel_configs:
          - source_labels: [__meta_kubernetes_pod_node_name]
            action: replace
            target_label: kubernetes_node

prometheus-adapter:
  # -- Normally, this chart will be installed if `scaling.auto.enabled` is true. However, if you wish
  # to manage the Prometheus adapter in your cluster on your own and not as part of the Deepgram Helm chart,
  # you can force it to not be installed by setting this to `false`.
  includeDependency:
  prometheus:
    url: http://dg-prometheus-stack-prometheus.{{ .Release.Namespace }}.svc
  rules:
    default: false
    external:
      - name:
          as: "engine_active_requests_stt_streaming"
        seriesQuery: 'engine_active_requests{kind="stream"}'
        metricsQuery: 'avg(engine_active_requests{kind="stream"})'
        resources:
          overrides:
            namespace: { resource: "namespace" }
            pod: { resource: "pod" }
            service: { resource: "service" }
      - name:
          as: "engine_active_requests_stt_batch"
        seriesQuery: 'engine_active_requests{kind="batch"}'
        metricsQuery: 'avg(engine_active_requests{kind="batch"})'
        resources:
          overrides:
            namespace: { resource: "namespace" }
            pod: { resource: "pod" }
            service: { resource: "service" }
      - name:
          as: "engine_active_requests_tts_batch"
        seriesQuery: 'engine_active_requests{kind="tts"}'
        metricsQuery: 'avg(engine_active_requests{kind="tts"})'
        resources:
          overrides:
            namespace: { resource: "namespace" }
            pod: { resource: "pod" }
            service: { resource: "service" }
      - name:
          as: "engine_estimated_stream_capacity"
        seriesQuery: 'engine_active_requests{kind="stream"}'
        metricsQuery: 'avg_over_time((sum(engine_active_requests{kind="stream"}) / sum(engine_estimated_stream_capacity))[1m:1m])'
        resources:
          overrides:
            namespace: { resource: "namespace" }
            pod: { resource: "pod" }
            service: { resource: "service" }
      - name:
          as: "engine_requests_active_to_max_ratio"
        seriesQuery: "engine_max_active_requests"
        metricsQuery: "avg_over_time((sum(engine_active_requests) / sum(engine_max_active_requests))[1m:1m])"
        resources:
          overrides:
            namespace: { resource: "namespace" }
            pod: { resource: "pod" }
            service: { resource: "service" }
      - name:
          as: "engine_to_api_pod_ratio"
        seriesQuery: 'kube_deployment_labels{label_app="deepgram-engine"}'
        metricsQuery: '(sum(kube_deployment_status_replicas and on(deployment) kube_deployment_labels{label_app="deepgram-engine"})) / (sum(kube_deployment_status_replicas and on(deployment) kube_deployment_labels{label_app="deepgram-api"}))'
        resources:
          overrides:
            namespace: { resource: "namespace" }
            pod: { resource: "pod" }
      # Average GPU utilization (%) for autoscaling
      - name:
          as: "engine_avg_gpu_utilization"
        seriesQuery: 'DCGM_FI_DEV_GPU_UTIL{container="deepgram-engine"}'
        metricsQuery: 'avg(avg_over_time(DCGM_FI_DEV_GPU_UTIL{container="deepgram-engine"}[1m]))'
        resources:
          overrides:
            namespace: { resource: "namespace" }
            pod: { resource: "pod" }
